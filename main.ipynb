{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "from torchtext.data import get_tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 28\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "sequence_length = 28\n",
    "learning_rate = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/en-de/train.ende.df.short.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "tokenizer = get_tokenizer(None)\n",
    "data[\"orig\"] = tokenizer(data[\"original\"].str)\n",
    "data[\"trans\"] = tokenizer(data[\"translation\"].str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                  [100, 100, 100]\n",
       "1                     [61, 70, 87]\n",
       "2                     [52, 45, 49]\n",
       "3                     [61, 55, 85]\n",
       "4                     [91, 89, 87]\n",
       "                   ...            \n",
       "6995    [100, 95, 87, 100, 78, 85]\n",
       "6996                 [100, 93, 80]\n",
       "6997                  [63, 76, 70]\n",
       "6998                [70, 100, 100]\n",
       "6999                [80, 100, 100]\n",
       "Name: scores, Length: 7000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def toList(input):\n",
    "    return [float(entry) for entry in input[1:-1].split(', ')]\n",
    "#display(data[0:32])\n",
    "#data[\"scores\"].str.len().max()\n",
    "data[\"scores\"] = data[\"scores\"].astype(object)\n",
    "#turnlist = np.vectorize(toList)\n",
    "#data[\"scores_list\"] = turnlist(data[\"scores\"]).astype(object)\n",
    "# measurer = np.vectorize(len)\n",
    "display(data[\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize network (try out just using simple RNN, or GRU, and then compare with LSTM)\n",
    "model = nn.Transformer(nhead=16, num_encoder_layers=12).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "out = transformer_model(src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/cameronbennett/Desktop/quality-est/main.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/quality-est/main.ipynb#ch0000005?line=0'>1</a>\u001b[0m xlmr \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mhub\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mpytorch/fairseq\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mxlmr.large\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/quality-est/main.ipynb#ch0000005?line=1'>2</a>\u001b[0m xlmr\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py:404\u001b[0m, in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=400'>401</a>\u001b[0m \u001b[39mif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgithub\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=401'>402</a>\u001b[0m     repo_or_dir \u001b[39m=\u001b[39m _get_cache_or_reload(repo_or_dir, force_reload, verbose, skip_validation)\n\u001b[0;32m--> <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=403'>404</a>\u001b[0m model \u001b[39m=\u001b[39m _load_local(repo_or_dir, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=404'>405</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py:430\u001b[0m, in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=426'>427</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, hubconf_dir)\n\u001b[1;32m    <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=428'>429</a>\u001b[0m hubconf_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(hubconf_dir, MODULE_HUBCONF)\n\u001b[0;32m--> <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=429'>430</a>\u001b[0m hub_module \u001b[39m=\u001b[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001b[1;32m    <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=431'>432</a>\u001b[0m entry \u001b[39m=\u001b[39m _load_entry_from_hubconf(hub_module, model)\n\u001b[1;32m    <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=432'>433</a>\u001b[0m model \u001b[39m=\u001b[39m entry(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py:76\u001b[0m, in \u001b[0;36m_import_module\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=73'>74</a>\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mmodule_from_spec(spec)\n\u001b[1;32m     <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=74'>75</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(spec\u001b[39m.\u001b[39mloader, Loader)\n\u001b[0;32m---> <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=75'>76</a>\u001b[0m spec\u001b[39m.\u001b[39;49mloader\u001b[39m.\u001b[39;49mexec_module(module)\n\u001b[1;32m     <a href='file:///Users/cameronbennett/miniforge3/envs/pytorch_m1/lib/python3.8/site-packages/torch/hub.py?line=76'>77</a>\u001b[0m \u001b[39mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:843\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/hubconf.py:39\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/hubconf.py?line=34'>35</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMissing dependencies: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(missing_deps)))\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/hubconf.py?line=37'>38</a>\u001b[0m \u001b[39m# only do fairseq imports after checking for dependencies\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/hubconf.py?line=38'>39</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfairseq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhub_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa; noqa\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/hubconf.py?line=39'>40</a>\u001b[0m     BPEHubInterface \u001b[39mas\u001b[39;00m bpe,\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/hubconf.py?line=40'>41</a>\u001b[0m     TokenizerHubInterface \u001b[39mas\u001b[39;00m tokenizer,\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/hubconf.py?line=41'>42</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/hubconf.py?line=42'>43</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfairseq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m MODEL_REGISTRY  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/hubconf.py?line=45'>46</a>\u001b[0m \u001b[39m# torch.hub doesn't build Cython components, so if they are not found then try\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/hubconf.py?line=46'>47</a>\u001b[0m \u001b[39m# to build them here\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/__init__.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/__init__.py?line=28'>29</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfairseq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataclass\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minitialize\u001b[39;00m \u001b[39mimport\u001b[39;00m hydra_init\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/__init__.py?line=30'>31</a>\u001b[0m hydra_init()\n\u001b[0;32m---> <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/__init__.py?line=32'>33</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfairseq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcriterions\u001b[39;00m  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/__init__.py?line=33'>34</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfairseq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistributed\u001b[39;00m  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/__init__.py?line=34'>35</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfairseq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m  \u001b[39m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfairseq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcriterions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfairseq_criterion\u001b[39;00m \u001b[39mimport\u001b[39;00m (  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=11'>12</a>\u001b[0m     FairseqCriterion,\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=12'>13</a>\u001b[0m     LegacyFairseqCriterion,\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=13'>14</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39momegaconf\u001b[39;00m \u001b[39mimport\u001b[39;00m DictConfig\n\u001b[0;32m---> <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=17'>18</a>\u001b[0m (\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=18'>19</a>\u001b[0m     build_criterion_,\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=19'>20</a>\u001b[0m     register_criterion,\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=20'>21</a>\u001b[0m     CRITERION_REGISTRY,\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=21'>22</a>\u001b[0m     CRITERION_DATACLASS_REGISTRY,\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=22'>23</a>\u001b[0m ) \u001b[39m=\u001b[39m registry\u001b[39m.\u001b[39msetup_registry(\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=23'>24</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m--criterion\u001b[39m\u001b[39m\"\u001b[39m, base_class\u001b[39m=\u001b[39mFairseqCriterion, default\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcross_entropy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=24'>25</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_criterion\u001b[39m(cfg: DictConfig, task):\n\u001b[1;32m     <a href='file:///Users/cameronbennett/.cache/torch/hub/pytorch_fairseq_main/fairseq/criterions/__init__.py?line=28'>29</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m build_criterion_(cfg, task)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "xlmr = torch.hub.load('pytorch/fairseq', 'xlmr.large')\n",
    "xlmr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1428.82861328125\n",
      "199 965.3364868164062\n",
      "299 653.7255249023438\n",
      "399 444.0448913574219\n",
      "499 302.8262023925781\n",
      "599 207.6285858154297\n",
      "699 143.39334106445312\n",
      "799 100.00811004638672\n",
      "899 70.67574310302734\n",
      "999 50.823944091796875\n",
      "1099 37.3746337890625\n",
      "1199 28.253101348876953\n",
      "1299 22.06001853942871\n",
      "1399 17.85055923461914\n",
      "1499 14.986246109008789\n",
      "1599 13.0349702835083\n",
      "1699 11.704204559326172\n",
      "1799 10.795587539672852\n",
      "1899 10.174476623535156\n",
      "1999 9.74942398071289\n",
      "Result: y = -0.02436021901667118 + 0.8372358679771423 x + 0.004202541895210743 x^2 + -0.09055598080158234 x^3\n"
     ]
    }
   ],
   "source": [
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4226af806255234de6cd334e9c37fc7171783016e547778141af0c6acc89dcf5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
